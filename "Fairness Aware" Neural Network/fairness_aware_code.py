# -*- coding: utf-8 -*-
"""STAT 27725 Final Project Code

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1twwAc_datpf6frQ0pSjbaztFoYUD3u4H
"""

from google.colab import drive
drive.mount('/content/drive')

"""**BASELINE MODEL**"""

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score
import tensorflow as tf
from tensorflow.keras.layers import Input, Dense, Dropout
from tensorflow.keras.models import Model
import matplotlib.pyplot as plt
import seaborn as sns


np.random.seed(0)
tf.random.set_seed(0)
data_path = '/content/drive/MyDrive/adult (4).data'

def import_data(filepath):
    columns = ['age', 'work', 'fnlwgt', 'education', 'education_num',
               'marital_status', 'occupation', 'relationship', 'race', 'sex',
               'capital_gain', 'capital_loss', 'hours_per_week', 'country', 'target']
    data = (pd.read_csv(filepath, names=columns, na_values="?",
                        sep=r'\s*,\s*', engine='python'))

    sensitive_cols = ['sex', 'race']
    Z_data = (data.loc[:, sensitive_cols]
              .assign(sex=lambda df: (df['sex'] == 'Female').astype(int))
              .assign(race=lambda df: (df['race'] != 'White').astype(int)))

    y_data = (data['target'] == '>50K').astype(int)

    X_data = (data
              .drop(columns=['target', 'sex', 'race'])
              .fillna('Unknown')
              .pipe(pd.get_dummies, drop_first=True))

    return X_data, y_data, Z_data

def prepare_train_test_sets(X, y, Z):
    X_train_set, X_test_set, y_train_set, y_test_set, Z_train_set, Z_test_set = train_test_split(
        X, y, Z, test_size=0.2, stratify=y, random_state=94)
    data_scaler = StandardScaler().fit(X_train_set)

    scaled_df = lambda df, scaler: pd.DataFrame(scaler.transform(df), columns=df.columns, index=df.index)
    X_train_set = X_train_set.pipe(scaled_df, data_scaler)
    X_test_set = X_test_set.pipe(scaled_df, data_scaler)

    return X_train_set, X_test_set, y_train_set, y_test_set, Z_train_set, Z_test_set

def build_nn_classifier(num_features):
    input_layer = Input(shape=(num_features,))
    layer1 = Dense(40, activation='relu')(input_layer)
    dropout_layer1 = Dropout(0.2)(layer1)
    layer2 = Dense(40, activation='relu')(dropout_layer1)
    dropout_layer2 = Dropout(0.2)(layer2)
    layer3 = Dense(40, activation="relu")(dropout_layer2)
    dropout_layer3 = Dropout(0.2)(layer3)
    output_layer = Dense(1, activation='sigmoid')(dropout_layer3)
    model = Model(inputs=[input_layer], outputs=[output_layer])
    model.compile(loss='binary_crossentropy', optimizer='adam')
    return model

def generate_report(pred_y, test_y, Z_test_set):
    print(f"Receiver Operating Characteristic - Area Under Curve: {roc_auc_score(test_y, pred_y):.2f}")
    print(f"Baseline Accuracy: {100*np.max([len(test_y[test_y==0]),len(test_y[test_y==1])])/len(test_y):.1f}%")
    print(f"Precision: {100*precision_score(test_y, pred_y>=0.5):.1f}%")
    print(f"Accuracy: {100*accuracy_score(test_y, (pred_y>=0.5)):.1f}%")
    print(f"Recall: {100*recall_score(test_y, pred_y>=0.5):.1f}%")
    print(f"Fairness metrics per protected Attribute:")
    for protected_attrib in ['sex', 'race']:
        print(f"\n           Protected class == {protected_attrib}")
        pos_rates = []
        tprs = []
        fprs = []
        for subclass in [0,1]:
            mask = Z_test_set[protected_attrib] == subclass
            pred_y_sub = pred_y[mask]
            test_y_sub = test_y[mask]
            pos_rate = (pred_y_sub >= 0.5).mean()
            tpr = ((pred_y_sub >= 0.5) & (test_y_sub == 1)).sum() / (test_y_sub == 1).sum()
            fpr = ((pred_y_sub >= 0.5) & (test_y_sub == 0)).sum() / (test_y_sub == 0).sum()
            pos_rates.append(pos_rate)
            tprs.append(tpr)
            fprs.append(fpr)
            print(f"              Subclass=={subclass}")
            print(f"Accuracy: {100*accuracy_score(test_y_sub, pred_y_sub>=0.5):.1f}%")
            print(f"Precision: {100*precision_score(test_y_sub, pred_y_sub >= 0.5):.1f}%")
            print(f"Recall: {100*recall_score(test_y_sub, pred_y_sub >= 0.5):.1f}%")
            correct_positives = (pred_y_sub>=0.5)*test_y_sub
            print(f"Samples: {len(pred_y_sub)} - Positives: {(pred_y_sub>=0.5).sum()} - Correct positives: {correct_positives.sum():.0f}")
            print(f"Positive rate: {pos_rate:.3f}")
            print(f"True positive rate: {tpr:.3f}")
            print(f"False positive rate: {fpr:.3f}")
        print(f"\nDemographic Parity for '{protected_attrib}': {abs(pos_rates[0] - pos_rates[1]):.3f}")
        print(f"Equalized Odds for '{protected_attrib}': TPR_diff={abs(tprs[0] - tprs[1]):.3f}, FPR_diff={abs(fprs[0] - fprs[1]):.3f}")


if __name__ == "__main__":
    X_data, y_data, Z_data = import_data(data_path)
    X_train_set, X_test_set, y_train_set, y_test_set, Z_train_set, Z_test_set = prepare_train_test_sets(X_data, y_data, Z_data)

    nn_model = build_nn_classifier(num_features=X_train_set.shape[1])
    model_history = nn_model.fit(X_train_set.values, y_train_set.values, epochs=20, verbose=1)

    pred_y = pd.Series(nn_model.predict(X_test_set.values).ravel(), index=y_test_set.index)
    generate_report(pred_y, y_test_set, Z_test_set)

    plt.figure(figsize=(10, 6))
    sns.kdeplot(pred_y[Z_test_set['sex'] == 0], color='blue', label='Male')
    sns.kdeplot(pred_y[Z_test_set['sex'] == 1], color='red', label='Female')
    plt.xlabel('Probability of income > 50k')
    plt.ylabel('Density')
    plt.title('KDE plot of predicted probabilities for income > 50k by Sex')
    plt.legend()
    plt.show()

    plt.figure(figsize=(10, 6))
    sns.kdeplot(pred_y[Z_test_set['race'] == 0], color='green', label='White')
    sns.kdeplot(pred_y[Z_test_set['race'] == 1], color='purple', label='Non-White')
    plt.xlabel('Probability of income > 50k')
    plt.ylabel('Density')
    plt.title('KDE plot of predicted probabilities for income > 50k by Race')
    plt.legend()
    plt.show()

"""**CUSTOM LOSS MODEL**

"""

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score
import tensorflow as tf
from tensorflow.keras.layers import Input, Dense, Dropout
from tensorflow.keras.models import Model
from tensorflow.keras import backend as K
from tensorflow.keras.losses import BinaryCrossentropy
import matplotlib.pyplot as plt
import seaborn as sns

np.random.seed(0)
tf.random.set_seed(0)
bce = tf.keras.losses.BinaryCrossentropy()

def custom_loss(alpha):
    def DI_loss_z(y_true, y_pred, z):
        z = tf.cast(z, tf.float32)
        y_pred_0 = y_pred*(1-z)
        y_pred_1 = y_pred*z
        ratio = tf.reduce_sum(1-z)/tf.reduce_sum(z)
        custom_loss = 1-tf.minimum(tf.reduce_mean(y_pred_1)*ratio/(tf.reduce_mean(y_pred_0)), (1/(tf.reduce_mean(y_pred_1)*ratio/(tf.reduce_mean(y_pred_0)))))
        return custom_loss

    def final_loss(y, y_pred):
        y_true, z_sex = y[:,0], y[:,1]
        y_pred = tf.transpose(y_pred)
        return bce(y_true, y_pred) + alpha[0]*DI_loss_z(y_true, y_pred, tf.cast(z_sex, tf.float32))
    return final_loss

def build_nn_classifier(num_features, alpha):
    input_layer = Input(shape=(num_features,))
    layer1 = Dense(40, activation='relu')(input_layer)
    dropout_layer1 = Dropout(0.2)(layer1)
    layer2 = Dense(40, activation='relu')(dropout_layer1)
    dropout_layer2 = Dropout(0.2)(layer2)
    layer3 = Dense(40, activation='relu')(dropout_layer2)
    dropout_layer3 = Dropout(0.2)(layer3)
    output_layer = Dense(1, activation='sigmoid')(dropout_layer3)
    model = Model(inputs=[input_layer], outputs=[output_layer])
    model.compile(loss=custom_loss(alpha), optimizer='adam', metrics=tf.keras.metrics.BinaryAccuracy(name='acc', dtype=None, threshold=0.5))
    return model

if __name__ == "__main__":
    X_data, y_data, Z_data = import_data(data_path)
    X_train_set, X_test_set, y_train_set, y_test_set, Z_train_set, Z_test_set = prepare_train_test_sets(X_data, y_data, Z_data)

    alpha = (0.35,)
    nn_model = build_nn_classifier(num_features=X_train_set.shape[1], alpha=alpha)

    Y_train = np.append(np.reshape(y_train_set.values, (y_train_set.shape[0],1)), Z_train_set['sex'].values[:, np.newaxis], axis=1)
    Y_test = np.append(np.reshape(y_test_set.values, (y_test_set.shape[0],1)), Z_test_set['sex'].values[:, np.newaxis], axis=1)

    model_history = nn_model.fit(X_train_set.values, Y_train, epochs=20, verbose=1, validation_data = (X_test_set.values, Y_test))

    pred_y = pd.Series(nn_model.predict(X_test_set.values).ravel(), index=y_test_set.index)
    generate_report(pred_y, y_test_set, Z_test_set)

    plt.figure(figsize=(10, 6))
    sns.kdeplot(pred_y[Z_test_set['sex'] == 0], color='blue', label='Male')
    sns.kdeplot(pred_y[Z_test_set['sex'] == 1], color='red', label='Female')
    plt.xlabel('Probability of income > 50k')
    plt.ylabel('Density')
    plt.title('KDE plot of predicted probabilities for income > 50k by Sex')
    plt.legend()
    plt.show()

    plt.figure(figsize=(10, 6))
    sns.kdeplot(pred_y[Z_test_set['race'] == 0], color='green', label='White')
    sns.kdeplot(pred_y[Z_test_set['race'] == 1], color='purple', label='Non-White')
    plt.xlabel('Probability of income > 50k')
    plt.ylabel('Density')
    plt.title('KDE plot of predicted probabilities for income > 50k by Race')
    plt.legend()
    plt.show()